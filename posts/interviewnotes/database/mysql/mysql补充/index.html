<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>MySQL补充 | RLTEA BLOG</title>
<meta name=keywords content="笔记,数据库,MySQL"><meta name=description content="MySQL补充
1 InnoDB中数据如何存放



InnoDB引擎中，一张表的数据是存放在“tableName.idb”表空间文件中的。

表空间由段（segment）、区（extent）、页（page）、行（row）组成。

行：记录按行存放
页：记录的读取写入是以页为单位，页是InnoDB存储引擎磁盘管理的最小单元。页的类型有数据页、undo log页、溢出页等。16KB。
区：表中数据量大的时候，为某个索引分配空间不再按照页为单位划分，而是以区为单位进行分配。1M。
段：表空间有索引段（B+Tree非叶子节点）、数据段（B+Tree叶子节点）、回滚段（MVCC）。



Compact行格式中，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。
记录的额外信息：

变长字段长度列表：存储变长字段的数据占用的大小，当数据表没有变长字段的时候，表里的行格式就不会有「变长字段长度列表」。
NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。（1标识该列为NULL，0标识不为NULL）。当数据表的字段都定义成 NOT NULL 的时，表里的行格式就不会有 NULL 值列表。
记录头信息：

delete_mask ：标识此条数据是否被删除。
next_record：下一条记录的位置。
record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。



记录的真实数据：
记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer。

row_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。
trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。
roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。

2 两阶段提交
事务提交后，redolog和binlog都要持久化到磁盘，但是这两个日志是独立的逻辑，可能会出现半成功的情况，也就是两个日志逻辑不一致：

如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。

导致从库的值是旧值，主库的是新值。


如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。

导致从库的值是新值，主库的是旧值。



MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。"><meta name=author content="RLTEA"><link rel=canonical href=https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql%E8%A1%A5%E5%85%85/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.258803b0f0cc9a4a109c6fe78a9d39f2e0437217d71c5c9848255af9250f2b1b.css integrity="sha256-JYgDsPDMmkoQnG/nip058uBDchfXHFyYSCVa+SUPKxs=" rel="preload stylesheet" as=style><link rel=icon href=https://roaraeonliou.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://roaraeonliou.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://roaraeonliou.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://roaraeonliou.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://roaraeonliou.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql%E8%A1%A5%E5%85%85/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="MySQL补充"><meta property="og:description" content="MySQL补充
1 InnoDB中数据如何存放



InnoDB引擎中，一张表的数据是存放在“tableName.idb”表空间文件中的。

表空间由段（segment）、区（extent）、页（page）、行（row）组成。

行：记录按行存放
页：记录的读取写入是以页为单位，页是InnoDB存储引擎磁盘管理的最小单元。页的类型有数据页、undo log页、溢出页等。16KB。
区：表中数据量大的时候，为某个索引分配空间不再按照页为单位划分，而是以区为单位进行分配。1M。
段：表空间有索引段（B+Tree非叶子节点）、数据段（B+Tree叶子节点）、回滚段（MVCC）。



Compact行格式中，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。
记录的额外信息：

变长字段长度列表：存储变长字段的数据占用的大小，当数据表没有变长字段的时候，表里的行格式就不会有「变长字段长度列表」。
NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。（1标识该列为NULL，0标识不为NULL）。当数据表的字段都定义成 NOT NULL 的时，表里的行格式就不会有 NULL 值列表。
记录头信息：

delete_mask ：标识此条数据是否被删除。
next_record：下一条记录的位置。
record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。



记录的真实数据：
记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer。

row_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。
trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。
roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。

2 两阶段提交
事务提交后，redolog和binlog都要持久化到磁盘，但是这两个日志是独立的逻辑，可能会出现半成功的情况，也就是两个日志逻辑不一致：

如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。

导致从库的值是旧值，主库的是新值。


如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。

导致从库的值是新值，主库的是旧值。



MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。"><meta property="og:type" content="article"><meta property="og:url" content="https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql%E8%A1%A5%E5%85%85/"><meta property="og:image" content="https://roaraeonliou.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-26T00:00:00+00:00"><meta property="og:site_name" content="RLTEA BLOG"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://roaraeonliou.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="MySQL补充"><meta name=twitter:description content="MySQL补充
1 InnoDB中数据如何存放



InnoDB引擎中，一张表的数据是存放在“tableName.idb”表空间文件中的。

表空间由段（segment）、区（extent）、页（page）、行（row）组成。

行：记录按行存放
页：记录的读取写入是以页为单位，页是InnoDB存储引擎磁盘管理的最小单元。页的类型有数据页、undo log页、溢出页等。16KB。
区：表中数据量大的时候，为某个索引分配空间不再按照页为单位划分，而是以区为单位进行分配。1M。
段：表空间有索引段（B+Tree非叶子节点）、数据段（B+Tree叶子节点）、回滚段（MVCC）。



Compact行格式中，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。
记录的额外信息：

变长字段长度列表：存储变长字段的数据占用的大小，当数据表没有变长字段的时候，表里的行格式就不会有「变长字段长度列表」。
NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。（1标识该列为NULL，0标识不为NULL）。当数据表的字段都定义成 NOT NULL 的时，表里的行格式就不会有 NULL 值列表。
记录头信息：

delete_mask ：标识此条数据是否被删除。
next_record：下一条记录的位置。
record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。



记录的真实数据：
记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer。

row_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。
trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。
roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。

2 两阶段提交
事务提交后，redolog和binlog都要持久化到磁盘，但是这两个日志是独立的逻辑，可能会出现半成功的情况，也就是两个日志逻辑不一致：

如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。

导致从库的值是旧值，主库的是新值。


如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。

导致从库的值是新值，主库的是旧值。



MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://roaraeonliou.github.io/posts/"},{"@type":"ListItem","position":2,"name":"MySQL补充","item":"https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql%E8%A1%A5%E5%85%85/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"MySQL补充","name":"MySQL补充","description":"MySQL补充 1 InnoDB中数据如何存放 InnoDB引擎中，一张表的数据是存放在“tableName.idb”表空间文件中的。\n表空间由段（segment）、区（extent）、页（page）、行（row）组成。\n行：记录按行存放 页：记录的读取写入是以页为单位，页是InnoDB存储引擎磁盘管理的最小单元。页的类型有数据页、undo log页、溢出页等。16KB。 区：表中数据量大的时候，为某个索引分配空间不再按照页为单位划分，而是以区为单位进行分配。1M。 段：表空间有索引段（B+Tree非叶子节点）、数据段（B+Tree叶子节点）、回滚段（MVCC）。 Compact行格式中，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。\n记录的额外信息：\n变长字段长度列表：存储变长字段的数据占用的大小，当数据表没有变长字段的时候，表里的行格式就不会有「变长字段长度列表」。 NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。（1标识该列为NULL，0标识不为NULL）。当数据表的字段都定义成 NOT NULL 的时，表里的行格式就不会有 NULL 值列表。 记录头信息： delete_mask ：标识此条数据是否被删除。 next_record：下一条记录的位置。 record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。 记录的真实数据：\n记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer。\nrow_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。 trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。 roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。 2 两阶段提交 事务提交后，redolog和binlog都要持久化到磁盘，但是这两个日志是独立的逻辑，可能会出现半成功的情况，也就是两个日志逻辑不一致：\n如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。 导致从库的值是旧值，主库的是新值。 如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。 导致从库的值是新值，主库的是旧值。 MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。\n","keywords":["笔记","数据库","MySQL"],"articleBody":"MySQL补充 1 InnoDB中数据如何存放 InnoDB引擎中，一张表的数据是存放在“tableName.idb”表空间文件中的。\n表空间由段（segment）、区（extent）、页（page）、行（row）组成。\n行：记录按行存放 页：记录的读取写入是以页为单位，页是InnoDB存储引擎磁盘管理的最小单元。页的类型有数据页、undo log页、溢出页等。16KB。 区：表中数据量大的时候，为某个索引分配空间不再按照页为单位划分，而是以区为单位进行分配。1M。 段：表空间有索引段（B+Tree非叶子节点）、数据段（B+Tree叶子节点）、回滚段（MVCC）。 Compact行格式中，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。\n记录的额外信息：\n变长字段长度列表：存储变长字段的数据占用的大小，当数据表没有变长字段的时候，表里的行格式就不会有「变长字段长度列表」。 NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。（1标识该列为NULL，0标识不为NULL）。当数据表的字段都定义成 NOT NULL 的时，表里的行格式就不会有 NULL 值列表。 记录头信息： delete_mask ：标识此条数据是否被删除。 next_record：下一条记录的位置。 record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。 记录的真实数据：\n记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer。\nrow_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。 trx_id：事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。 roll_pointer：这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。 2 两阶段提交 事务提交后，redolog和binlog都要持久化到磁盘，但是这两个日志是独立的逻辑，可能会出现半成功的情况，也就是两个日志逻辑不一致：\n如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。 导致从库的值是旧值，主库的是新值。 如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。 导致从库的值是新值，主库的是旧值。 MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。\n两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。\n2.1 两阶段提交过程 MySQL使用内部XA事务，由bin log作为协调者，存储引擎是参与者。\n当客户端执行commit语句或者自动提交时，MySQL内部开启XA事务，分两阶段完成XA提交的提交。\n从图中可看出，事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下：\nprepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）； commit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功； 2.2 异常重启会出现什么现象？ 不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，此时的 redo log 都处于 prepare 状态。\n在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：\n如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。 如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。 可以看到，对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。\n所以说，两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。\n2.3 两阶段提交有什么问题？ 两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：\n磁盘 I/O 次数高：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。 锁竞争激烈：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。 为什么两阶段提交的磁盘 I/O 次数会很高？ binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1：\n当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘； 当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘； 可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会至少调用 2 次刷盘操作，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。\n为什么锁竞争激烈？ 在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。 通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳。\n组提交 MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。\n引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：\nflush 阶段：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）； sync 阶段：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）； commit 阶段：各个事务按顺序做 InnoDB commit 操作； 上面的每个阶段都有一个队列，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。\n对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率。\n有 binlog 组提交，那有 redo log 组提交吗？ 这个要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。 在 MySQL 5.6 的组提交逻辑中，每个事务各自执行 prepare 阶段，也就是各自将 redo log 刷盘，这样就没办法对 redo log 进行组提交。 所以在 MySQL 5.7 版本中，做了个改进，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段。 这个优化是将 redo log 的刷盘延迟到了 flush 阶段之中，sync 阶段之前。通过延迟写 redo log 的方式，为 redolog 做了一次组写入，这样 binlog 和 redo log 都进行了优化。 接下来介绍每个阶段的过程，注意下面的过程针对的是“双 1” 配置（sync_binlog 和 innodb_flush_log_at_trx_commit 都配置为 1）。\nflush 阶段\n第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower：\n接着，获取队列中的事务组，由绿色事务组的 Leader 对 redo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘：\n完成了 prepare 阶段后，将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。\n从上面这个过程，可以知道 flush 阶段队列的作用是用于支撑 redo log 的组提交。\n如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。\nsync 阶段\n绿色这一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是会等待一段时间，这个等待的时长由 Binlog_group_commit_sync_delay 参数控制，目的是为了组合更多事务的 binlog，然后再一起刷盘，如下过程：\n不过，在等待的过程中，如果事务的数量提前达到了 Binlog_group_commit_sync_no_delay_count 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘，如下图：\n从上面的过程，可以知道 sync 阶段队列的作用是用于支持 binlog 的组提交。\n如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：\nbinlog_group_commit_sync_delay= N，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。 binlog_group_commit_sync_no_delay_count = N，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。 如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。\ncommit 阶段\n最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。\ncommit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率。\n2.4 MySQL 磁盘 I/O 很高，有什么优化的方法？ 现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率：\n设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。 3 Buffer Pool 3.1 为什么要有 Buffer Pool？ 虽然说 MySQL 的数据是存储在磁盘里的，但是也不能每次都从磁盘里面读取数据，这样性能是极差的。\n要想提升查询性能，加个缓存就行了嘛。所以，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。\n为此，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。\n有了缓冲池后：\n当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。 3.1.1 Buffer Pool 有多大？ Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 128MB 。\n可以通过调整 innodb_buffer_pool_size 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。\n3.1.2 Buffer Pool 缓存什么？ InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。\n在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。\n所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。\nBuffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。\n为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。\n控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页，如下图：\n上图中控制块和缓存页之间灰色部分称为碎片空间。\n为什么会有碎片空间呢？\n你想想啊，每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。 当然，如果你把 Buffer Pool 的大小设置的刚刚好的话，也可能不会产生碎片。\n查询一条记录，就只需要缓冲一条记录吗？ 不是的。 当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。\n3.2 如何管理 Buffer Pool？ 3.2.1 如何管理空闲页？ Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。\n那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。\n所以，为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 Free 链表（空闲链表）。\nFree 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。\nFree 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。\n有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。\n3.2.2 如何管理脏页？ 设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。\n那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。\n有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。\n3.2.3 如何提高缓存命中率？ Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中。\n要实现这个，最容易想到的就是 LRU（Least recently used）算法。\n该算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，从而腾出空间。\n简单的 LRU 算法的实现思路是这样的：\n当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。 比如下图，假设 LRU 链表长度为 5，LRU 链表从左到右有 1，2，3，4，5 的页。\n如果访问了 3 号的页，因为 3 号页在 Buffer Pool 里，所以把 3 号页移动到头部即可。\n而如果接下来，访问了 8 号页，因为 8 号页不在 Buffer Pool 里，所以需要先淘汰末尾的 5 号页，然后再将 8 号页加入到头部。\n到这里我们可以知道，Buffer Pool 里有三种页和链表来管理数据。\n图中：\nFree Page（空闲页），表示此页未被使用，位于 Free 链表； Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。 Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。 简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：\n预读失效； Buffer Pool 污染； 什么是预读失效？ 先来说说 MySQL 的预读机制。程序是有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。 所以，MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。 但是可能这些被提前加载进来的数据页，并没有被访问，相当于这个预读是白做了，这个就是预读失效。 如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。 如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。\n怎么解决预读失效而导致缓存命中率降低的问题？ 我们不能因为害怕预读失效，而将预读机制去掉，大部分情况下，局部性原理还是成立的。 要避免预读失效带来影响，最好就是让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长。 那到底怎么才能避免呢？ MySQL 是这样做的，它改进了 LRU 算法，将 LRU 划分了 2 个区域：old 区域 和 young 区域。\nyoung 区域在 LRU 链表的前半部分，old 区域则是在后半部分，如下图：\nold 区域占整个 LRU 链表长度的比例可以通过 innodb_old_blocks_pct 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。\n划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。\n接下来，给大家举个例子。\n假设有一个长度为 10 的 LRU 链表，其中 young 区域占比 70 %，old 区域占比 30 %。\n现在有个编号为 20 的页被预读了，这个页只会被插入到 old 区域头部，而 old 区域末尾的页（10号）会被淘汰掉。\n如果 20 号页一直不会被访问，它也没有占用到 young 区域的位置，而且还会比 young 区域的数据更早被淘汰出去。\n如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 young 区域的头部，young 区域末尾的页（7号），会被挤到 old 区域，作为 old 区域的头部，这个过程并不会有页被淘汰。\n虽然通过划分 old 区域 和 young 区域避免了预读失效带来的影响，但是还有个问题无法解决，那就是 Buffer Pool 污染的问题。\n什么是 Buffer Pool 污染？ 当某一个 SQL 语句扫描了大量的数据时，在 Buffer Pool 空间比较有限的情况下，可能会将 Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 Buffer Pool 污染。 注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。\n比如，在一个数据量非常大的表，执行了这条语句：\nselect * from t_user where name like \"%xiaolin%\"; 可能这个查询出来的结果就几条记录，但是由于这条语句会发生索引失效，所以这个查询过程是全表扫描的，接着会发生如下的过程：\n从磁盘读到的页加入到 LRU 链表的 old 区域头部； 当从页里读取行记录时，也就是页被访问的时候，就要将该页放到 young 区域头部； 接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里； 如此往复，直到扫描完表中的所有记录。 经过这一番折腾，原本 young 区域的热点数据都会被替换掉。\n举个例子，假设需要批量扫描：21，22，23，24，25 这五个页，这些页都会被逐一访问（读取页里的记录）。\n在批量访问这些数据的时候，会被逐一插入到 young 区域头部。\n可以看到，原本在 young 区域的热点数据 6 和 7 号页都被淘汰了，这就是 Buffer Pool 污染的问题。\n怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？\n像前面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。 LRU 链表中 young 区域就是热点数据，只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。 MySQL 是这样做的，进入到 young 区域条件增加了一个停留在 old 区域的时间判断。 具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：\n如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会被从 old 区域移动到 young 区域的头部； 如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到 young 区域的头部； 这个间隔时间是由 innodb_old_blocks_time 控制的，默认是 1000 ms。\n也就说，只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部，这样就解决了 Buffer Pool 污染的问题 。\n另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。\n3.2.4 脏页什么时候会被刷入磁盘？ 引入了 Buffer Pool 后，当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，但是磁盘中还是原数据。\n因此，脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘。\n可能大家担心，如果在脏页还没有来得及刷入到磁盘时，MySQL 宕机了，不就丢失数据了吗？\n这个不用担心，InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。\n下面几种情况会触发脏页的刷新：\n当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘； Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘； MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘； MySQL 正常关闭之前，会把所有的脏页刷入到磁盘； 在我们开启了慢 SQL 监控后，如果你发现**「偶尔」会出现一些用时稍长的 SQL**，这可能是因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致数据库操作抖动。\n如果间断出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。\n3.3 总结 Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。\nBuffer Pool 以页为单位缓冲数据，可以通过 innodb_buffer_pool_size 参数调整缓冲池的大小，默认是 128 M。\nInnodb 通过三种链表来管理缓页：\nFree List （空闲页链表），管理空闲页； Flush List （脏页链表），管理脏页； LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去。； InnoDB 对 LRU 做了一些优化，我们熟悉的 LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化：\n将 LRU 链表 分为young 和 old 两个区域，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。 当**「页被访问」且「 old 区域停留时间超过 innodb_old_blocks_time 阈值（默认为1秒）」**时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。 可以通过调整 innodb_old_blocks_pct 参数，设置 young 区域和 old 区域比例。\n在开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可因为脏页在刷新到磁盘时导致数据库性能抖动。如果在很短的时间出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。\n","wordCount":"1215","inLanguage":"en","image":"https://roaraeonliou.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-09-26T00:00:00Z","dateModified":"2024-09-26T00:00:00Z","author":{"@type":"Person","name":"RLTEA"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql%E8%A1%A5%E5%85%85/"},"publisher":{"@type":"Organization","name":"RLTEA BLOG","logo":{"@type":"ImageObject","url":"https://roaraeonliou.github.io/%3Clink%20/%20abs%20url%3E"}}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://roaraeonliou.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://roaraeonliou.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://roaraeonliou.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://roaraeonliou.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://roaraeonliou.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://roaraeonliou.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://roaraeonliou.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://roaraeonliou.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">MySQL补充</h1><div class=post-meta><span title='2024-09-26 00:00:00 +0000 UTC'>September 26, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1215 words&nbsp;·&nbsp;RLTEA&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/InterviewNotes/Database/MySQL/MySQL%e8%a1%a5%e5%85%85.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#mysql%e8%a1%a5%e5%85%85 aria-label=MySQL补充>MySQL补充</a></li><li><a href=#1-innodb%e4%b8%ad%e6%95%b0%e6%8d%ae%e5%a6%82%e4%bd%95%e5%ad%98%e6%94%be aria-label="1 InnoDB中数据如何存放">1 InnoDB中数据如何存放</a></li><li><a href=#2-%e4%b8%a4%e9%98%b6%e6%ae%b5%e6%8f%90%e4%ba%a4 aria-label="2 两阶段提交">2 两阶段提交</a><ul><li><a href=#21-%e4%b8%a4%e9%98%b6%e6%ae%b5%e6%8f%90%e4%ba%a4%e8%bf%87%e7%a8%8b aria-label="2.1 两阶段提交过程">2.1 两阶段提交过程</a></li><li><a href=#22-%e5%bc%82%e5%b8%b8%e9%87%8d%e5%90%af%e4%bc%9a%e5%87%ba%e7%8e%b0%e4%bb%80%e4%b9%88%e7%8e%b0%e8%b1%a1 aria-label="2.2 异常重启会出现什么现象？">2.2 <strong>异常重启会出现什么现象？</strong></a></li><li><a href=#23-%e4%b8%a4%e9%98%b6%e6%ae%b5%e6%8f%90%e4%ba%a4%e6%9c%89%e4%bb%80%e4%b9%88%e9%97%ae%e9%a2%98 aria-label="2.3 两阶段提交有什么问题？">2.3 两阶段提交有什么问题？</a><ul><ul><li><a href=#%e7%bb%84%e6%8f%90%e4%ba%a4 aria-label=组提交>组提交</a></li></ul></ul></li><li><a href=#24-mysql-%e7%a3%81%e7%9b%98-io-%e5%be%88%e9%ab%98%e6%9c%89%e4%bb%80%e4%b9%88%e4%bc%98%e5%8c%96%e7%9a%84%e6%96%b9%e6%b3%95 aria-label="2.4 MySQL 磁盘 I/O 很高，有什么优化的方法？">2.4 MySQL 磁盘 I/O 很高，有什么优化的方法？</a></li></ul></li><li><a href=#3-buffer-pool aria-label="3 Buffer Pool">3 Buffer Pool</a><ul><li><a href=#31-%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e6%9c%89-buffer-pool aria-label="3.1 为什么要有 Buffer Pool？">3.1 为什么要有 Buffer Pool？</a><ul><li><a href=#311-buffer-pool-%e6%9c%89%e5%a4%9a%e5%a4%a7 aria-label="3.1.1 Buffer Pool 有多大？">3.1.1 Buffer Pool 有多大？</a></li><li><a href=#312-buffer-pool-%e7%bc%93%e5%ad%98%e4%bb%80%e4%b9%88 aria-label="3.1.2 Buffer Pool 缓存什么？">3.1.2 Buffer Pool 缓存什么？</a></li></ul></li><li><a href=#32-%e5%a6%82%e4%bd%95%e7%ae%a1%e7%90%86-buffer-pool aria-label="3.2 如何管理 Buffer Pool？">3.2 如何管理 Buffer Pool？</a><ul><li><a href=#321-%e5%a6%82%e4%bd%95%e7%ae%a1%e7%90%86%e7%a9%ba%e9%97%b2%e9%a1%b5 aria-label="3.2.1 如何管理空闲页？">3.2.1 如何管理空闲页？</a></li><li><a href=#322-%e5%a6%82%e4%bd%95%e7%ae%a1%e7%90%86%e8%84%8f%e9%a1%b5 aria-label="3.2.2 如何管理脏页？">3.2.2 如何管理脏页？</a></li><li><a href=#323-%e5%a6%82%e4%bd%95%e6%8f%90%e9%ab%98%e7%bc%93%e5%ad%98%e5%91%bd%e4%b8%ad%e7%8e%87 aria-label="3.2.3 如何提高缓存命中率？">3.2.3 如何提高缓存命中率？</a></li><li><a href=#324-%e8%84%8f%e9%a1%b5%e4%bb%80%e4%b9%88%e6%97%b6%e5%80%99%e4%bc%9a%e8%a2%ab%e5%88%b7%e5%85%a5%e7%a3%81%e7%9b%98 aria-label="3.2.4 脏页什么时候会被刷入磁盘？">3.2.4 脏页什么时候会被刷入磁盘？</a></li></ul></li><li><a href=#33-%e6%80%bb%e7%bb%93 aria-label="3.3 总结">3.3 总结</a></li></ul></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h1 id=mysql补充>MySQL补充<a hidden class=anchor aria-hidden=true href=#mysql补充>#</a></h1><h1 id=1-innodb中数据如何存放>1 InnoDB中数据如何存放<a hidden class=anchor aria-hidden=true href=#1-innodb中数据如何存放>#</a></h1><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/e8d38bc28e035d84c29ffcd356d46212.png alt=image.png></p><blockquote><p>InnoDB引擎中，一张表的数据是存放在“tableName.idb”表空间文件中的。</p></blockquote><p>表空间由段（segment）、区（extent）、页（page）、行（row）组成。</p><ul><li>行：记录按行存放</li><li>页：记录的读取写入是以页为单位，页是InnoDB存储引擎磁盘管理的最小单元。页的类型有数据页、undo log页、溢出页等。16KB。</li><li>区：表中数据量大的时候，为某个索引分配空间不再按照页为单位划分，而是以区为单位进行分配。1M。</li><li>段：表空间有索引段（B+Tree非叶子节点）、数据段（B+Tree叶子节点）、回滚段（MVCC）。</li></ul><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/a5851e3ff3e62fcead99e965243d19ed.png alt=image.png></p><p>Compact行格式中，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。</p><p>记录的额外信息：</p><ul><li>变长字段长度列表：存储变长字段的数据占用的大小，<strong>当数据表没有变长字段的时候，表里的行格式就不会有「变长字段长度列表」</strong>。</li><li>NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。（1标识该列为NULL，0标识不为NULL）。<strong>当数据表的字段都定义成 NOT NULL 的时，表里的行格式就不会有 NULL 值列表</strong>。</li><li>记录头信息：<ul><li>delete_mask ：标识此条数据是否被删除。</li><li>next_record：下一条记录的位置。</li><li>record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录。</li></ul></li></ul><p>记录的真实数据：</p><p>记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer。</p><ul><li>row_id：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。<strong>row_id不是必需的，占用 6 个字节。</strong></li><li>trx_id：事务id，表示这个数据是由哪个事务生成的。 <strong>trx_id是必需的，占用 6 个字节。</strong></li><li>roll_pointer：这条记录上一个版本的指针。<strong>roll_pointer 是必需的，占用 7 个字节。</strong></li></ul><h1 id=2-两阶段提交>2 两阶段提交<a hidden class=anchor aria-hidden=true href=#2-两阶段提交>#</a></h1><p>事务提交后，redolog和binlog都要持久化到磁盘，但是这两个日志是独立的逻辑，可能会出现半成功的情况，也就是两个日志逻辑不一致：</p><ul><li><strong>如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。</strong><ul><li>导致从库的值是旧值，主库的是新值。</li></ul></li><li><strong>如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。</strong><ul><li>导致从库的值是新值，主库的是旧值。</li></ul></li></ul><p><strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。</p><p><strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。</p><h2 id=21-两阶段提交过程>2.1 两阶段提交过程<a hidden class=anchor aria-hidden=true href=#21-两阶段提交过程>#</a></h2><p>MySQL使用<strong>内部XA事务</strong>，由bin log作为协调者，存储引擎是参与者。</p><p>当客户端执行commit语句或者自动提交时，MySQL内部开启XA事务，分两阶段完成XA提交的提交。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/760071866885d7729706867713c951d1.png alt=image.png></p><p>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p><ul><li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；</li><li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</li></ul><h2 id=22-异常重启会出现什么现象>2.2 <strong>异常重启会出现什么现象？</strong><a hidden class=anchor aria-hidden=true href=#22-异常重启会出现什么现象>#</a></h2><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/93cef0a8f0a7c1668ac6b5a4dba2b7e8.png alt=image.png></p><p>不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，<strong>此时的 redo log 都处于 prepare 状态</strong>。</p><p>在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：</p><ul><li><strong>如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务</strong>。对应时刻 A 崩溃恢复的情况。</li><li><strong>如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务</strong>。对应时刻 B 崩溃恢复的情况。</li></ul><p>可以看到，<strong>对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID</strong>，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。</p><p>所以说，<strong>两阶段提交是以 binlog 写成功为事务提交成功的标识</strong>，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。</p><h2 id=23-两阶段提交有什么问题>2.3 两阶段提交有什么问题？<a hidden class=anchor aria-hidden=true href=#23-两阶段提交有什么问题>#</a></h2><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p><ul><li><strong>磁盘 I/O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li><li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li></ul><blockquote><blockquote><p>为什么两阶段提交的磁盘 I/O 次数会很高？
binlog 和 redo log 在内存中都对应的缓存空间，binlog 会缓存在 binlog cache，redo log 会缓存在 redo log buffer，它们持久化到磁盘的时机分别由下面这两个参数控制。一般我们为了避免日志丢失的风险，会将这两个参数设置为 1：</p></blockquote></blockquote><ul><li>当 sync_binlog = 1 的时候，表示每次提交事务都会将 binlog cache 里的 binlog 直接持久到磁盘；</li><li>当 innodb_flush_log_at_trx_commit = 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘；</li></ul><p>可以看到，如果 sync_binlog 和 当 innodb_flush_log_at_trx_commit 都设置为 1，那么在每个事务提交过程中， 都会<strong>至少调用 2 次刷盘操作</strong>，一次是 redo log 刷盘，一次是 binlog 落盘，所以这会成为性能瓶颈。</p><blockquote><blockquote><p>为什么锁竞争激烈？
在早期的 MySQL 版本中，通过使用 prepare_commit_mutex 锁来保证事务提交的顺序，在一个事务获取到锁时才能进入 prepare 阶段，一直到 commit 阶段结束才能释放锁，下个事务才可以继续进行 prepare 操作。
通过加锁虽然完美地解决了顺序一致性的问题，但在并发量较大的时候，就会导致对锁的争用，性能不佳。</p></blockquote></blockquote><h4 id=组提交>组提交<a hidden class=anchor aria-hidden=true href=#组提交>#</a></h4><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数</strong>，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。</p><p>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p><ul><li><strong>flush 阶段</strong>：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；</li><li><strong>sync 阶段</strong>：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；</li><li><strong>commit 阶段</strong>：各个事务按顺序做 InnoDB commit 操作；</li></ul><p>上面的<strong>每个阶段都有一个队列</strong>，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/ccec3ab525096580fd603a5659d8149c.png alt=image.png></p><p>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，<strong>锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率</strong>。</p><blockquote><blockquote><p><strong>有 binlog 组提交，那有 redo log 组提交吗？</strong> 这个要看 MySQL 版本，MySQL 5.6 没有 redo log 组提交，MySQL 5.7 有 redo log 组提交。
在 MySQL 5.6 的组提交逻辑中，每个事务各自执行 prepare 阶段，也就是各自将 redo log 刷盘，这样就没办法对 redo log 进行组提交。
所以在 MySQL 5.7 版本中，做了个改进，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段，也就是说 prepare 阶段融合在了 flush 阶段。
这个优化是将 redo log 的刷盘延迟到了 flush 阶段之中，sync 阶段之前。通过延迟写 redo log 的方式，为 redolog 做了一次组写入，这样 binlog 和 redo log 都进行了优化。
接下来介绍每个阶段的过程，注意下面的过程针对的是“双 1” 配置（sync_binlog 和 innodb_flush_log_at_trx_commit 都配置为 1）。</p></blockquote></blockquote><blockquote><p>flush 阶段</p></blockquote><p>第一个事务会成为 flush 阶段的 Leader，此时后面到来的事务都是 Follower：</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/e0a8e8b4186eeec3ec6e8f93c0a1094c.png alt=image.png></p><p>接着，获取队列中的事务组，由绿色事务组的 Leader 对 redo log 做一次 write + fsync，即一次将同组事务的 redolog 刷盘：</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/9b0cda53a3469e09d9e370767f0431d4.png alt=image.png></p><p>完成了 prepare 阶段后，将绿色这一组事务执行过程中产生的 binlog 写入 binlog 文件（调用 write，不会调用 fsync，所以不会刷盘，binlog 缓存在操作系统的文件系统中）。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/f699866941ee8d575273a67b25064974.png alt=image.png></p><p>从上面这个过程，可以知道 flush 阶段队列的作用是<strong>用于支撑 redo log 的组提交</strong>。</p><p>如果在这一步完成后数据库崩溃，由于 binlog 中没有该组事务的记录，所以 MySQL 会在重启后回滚该组事务。</p><blockquote><p>sync 阶段</p></blockquote><p>绿色这一组事务的 binlog 写入到 binlog 文件后，并不会马上执行刷盘的操作，而是<strong>会等待一段时间</strong>，这个等待的时长由 <code>Binlog_group_commit_sync_delay</code> 参数控制，<strong>目的是为了组合更多事务的 binlog，然后再一起刷盘</strong>，如下过程：</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/6fe6ea0eb077e1a326d3c1c1f69a9269.png alt=image.png></p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/bad57a473bdea09bf798b24ab1374633.png alt=image.png></p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/07b3561397af8042e51a1f17619061e2.png alt=image.png></p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/418d7b4d0774e06bd1bd9938df793872.png alt=image.png></p><p>不过，在等待的过程中，如果事务的数量提前达到了 <code>Binlog_group_commit_sync_no_delay_count</code> 参数设置的值，就不用继续等待了，就马上将 binlog 刷盘，如下图：</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/882652d7d582b76852b2e531d989d615.png alt=image.png></p><p>从上面的过程，可以知道 sync 阶段队列的作用是<strong>用于支持 binlog 的组提交</strong>。</p><p>如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：</p><ul><li><code>binlog_group_commit_sync_delay= N</code>，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。</li><li><code>binlog_group_commit_sync_no_delay_count = N</code>，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。</li></ul><p>如果在这一步完成后数据库崩溃，由于 binlog 中已经有了事务记录，MySQL会在重启后通过 redo log 刷盘的数据继续进行事务的提交。</p><blockquote><blockquote><p>commit 阶段</p></blockquote></blockquote><p>最后进入 commit 阶段，调用引擎的提交事务接口，将 redo log 状态设置为 commit。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/be37c92c88cae77fd657b5e2d86532b4.png alt=image.png></p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/e2a05d0c188087afbcff939ec883aa54.png alt=image.png></p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/b35b1a6deb182f32755a78b53131cb59.png alt=image.png></p><p>commit 阶段队列的作用是承接 sync 阶段的事务，完成最后的引擎提交，使得 sync 可以尽早的处理下一组事务，最大化组提交的效率。</p><h2 id=24-mysql-磁盘-io-很高有什么优化的方法>2.4 MySQL 磁盘 I/O 很高，有什么优化的方法？<a hidden class=anchor aria-hidden=true href=#24-mysql-磁盘-io-很高有什么优化的方法>#</a></h2><p>现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率：</p><ul><li>设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。</li><li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。</li><li>将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。</li></ul><h1 id=3-buffer-pool>3 Buffer Pool<a hidden class=anchor aria-hidden=true href=#3-buffer-pool>#</a></h1><h2 id=31-为什么要有-buffer-pool>3.1 为什么要有 Buffer Pool？<a hidden class=anchor aria-hidden=true href=#31-为什么要有-buffer-pool>#</a></h2><p>虽然说 MySQL 的数据是存储在磁盘里的，但是也不能每次都从磁盘里面读取数据，这样性能是极差的。</p><p>要想提升查询性能，加个缓存就行了嘛。所以，当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。</p><p>为此，Innodb 存储引擎设计了一个<strong>缓冲池（<em>Buffer Pool</em>）</strong>，来提高数据库的读写性能。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/427b1d2fe750fcb1a912c0accc753b46.png alt=image.png></p><p>有了缓冲池后：</p><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。</li></ul><h3 id=311-buffer-pool-有多大>3.1.1 Buffer Pool 有多大？<a hidden class=anchor aria-hidden=true href=#311-buffer-pool-有多大>#</a></h3><p>Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 <code>128MB</code> 。</p><p>可以通过调整 <code>innodb_buffer_pool_size</code> 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。</p><h3 id=312-buffer-pool-缓存什么>3.1.2 Buffer Pool 缓存什么？<a hidden class=anchor aria-hidden=true href=#312-buffer-pool-缓存什么>#</a></h3><p>InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。</p><p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><p>所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。</p><p>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/2e212d640aabb41cc1763843aa84cd2d.png alt=image.png></p><p>为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个<strong>控制块</strong>，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。</p><p>控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页，如下图：</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/ceed483efbddf3b9d72850d128a71456.png alt=image.png></p><p>上图中控制块和缓存页之间灰色部分称为碎片空间。</p><blockquote><blockquote><p><strong>为什么会有碎片空间呢？</strong></p></blockquote></blockquote><blockquote><blockquote><p>你想想啊，每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。
当然，如果你把 Buffer Pool 的大小设置的刚刚好的话，也可能不会产生碎片。</p></blockquote></blockquote><blockquote><p><strong>查询一条记录，就只需要缓冲一条记录吗？</strong> 不是的。
当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。</p></blockquote><h2 id=32-如何管理-buffer-pool>3.2 如何管理 Buffer Pool？<a hidden class=anchor aria-hidden=true href=#32-如何管理-buffer-pool>#</a></h2><h3 id=321-如何管理空闲页>3.2.1 如何管理空闲页？<a hidden class=anchor aria-hidden=true href=#321-如何管理空闲页>#</a></h3><p>Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。</p><p>那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。</p><p>所以，为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 <strong>Free 链表</strong>（空闲链表）。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/84eeeba6b1c1be3447001fe8c41568e3.png alt=image.png></p><p>Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。</p><p>Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。</p><p>有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。</p><h3 id=322-如何管理脏页>3.2.2 如何管理脏页？<a hidden class=anchor aria-hidden=true href=#322-如何管理脏页>#</a></h3><p>设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为<strong>脏页</strong>，然后再由后台线程将脏页写入到磁盘。</p><p>那为了能快速知道哪些缓存页是脏的，于是就设计出 <strong>Flush 链表</strong>，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/d33d27cd8c512d19bfc84ebc4f5429a4.png alt=image.png></p><p>有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。</p><h3 id=323-如何提高缓存命中率>3.2.3 如何提高缓存命中率？<a hidden class=anchor aria-hidden=true href=#323-如何提高缓存命中率>#</a></h3><p>Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中。</p><p>要实现这个，最容易想到的就是 LRU（Least recently used）算法。</p><p>该算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，从而腾出空间。</p><p>简单的 LRU 算法的实现思路是这样的：</p><ul><li>当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。</li><li>当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。</li></ul><p>比如下图，假设 LRU 链表长度为 5，LRU 链表从左到右有 1，2，3，4，5 的页。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/0069cd7016eeed63acdaaeda6837771f.png alt=image.png></p><p>如果访问了 3 号的页，因为 3 号页在 Buffer Pool 里，所以把 3 号页移动到头部即可。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/e2c5b683ec610503374f43c413c622cf.png alt=image.png></p><p>而如果接下来，访问了 8 号页，因为 8 号页不在 Buffer Pool 里，所以需要先淘汰末尾的 5 号页，然后再将 8 号页加入到头部。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/458479aa53c70155af9dea24ecd53a71.png alt=image.png></p><p>到这里我们可以知道，Buffer Pool 里有三种页和链表来管理数据。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/acf5fc71a4c9208987854f44b57f5c10.png alt=image.png></p><p>图中：</p><ul><li>Free Page（空闲页），表示此页未被使用，位于 Free 链表；</li><li>Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。</li><li>Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。</li></ul><p>简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：</p><ul><li>预读失效；</li><li>Buffer Pool 污染；</li></ul><blockquote><blockquote><p><strong>什么是预读失效？</strong> 先来说说 MySQL 的预读机制。程序是有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。
所以，MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。
但是可能这些<strong>被提前加载进来的数据页，并没有被访问</strong>，相当于这个预读是白做了，这个就是<strong>预读失效</strong>。
如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。
如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。</p></blockquote></blockquote><blockquote><p><strong>怎么解决预读失效而导致缓存命中率降低的问题？</strong> 我们不能因为害怕预读失效，而将预读机制去掉，大部分情况下，局部性原理还是成立的。
要避免预读失效带来影响，最好就是<strong>让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长</strong>。
那到底怎么才能避免呢？
MySQL 是这样做的，它改进了 LRU 算法，将 LRU 划分了 2 个区域：<strong>old 区域 和 young 区域</strong>。</p></blockquote><p>young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，如下图：</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/2e12dc2a93a9b3c84cc69bccbe6414e8.png alt=image.png></p><p>old 区域占整个 LRU 链表长度的比例可以通过 <code>innodb_old_blocks_pct</code> 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。</p><p><strong>划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部</strong>。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。</p><p>接下来，给大家举个例子。</p><p>假设有一个长度为 10 的 LRU 链表，其中 young 区域占比 70 %，old 区域占比 30 %。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/82751efb7f0ed89ba8a2f87597107bc9.png alt=image.png></p><p>现在有个编号为 20 的页被预读了，这个页只会被插入到 old 区域头部，而 old 区域末尾的页（10号）会被淘汰掉。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/775527559ed06d51f9e68ce652ed35ac.png alt=image.png></p><p>如果 20 号页一直不会被访问，它也没有占用到 young 区域的位置，而且还会比 young 区域的数据更早被淘汰出去。</p><p>如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 young 区域的头部，young 区域末尾的页（7号），会被挤到 old 区域，作为 old 区域的头部，这个过程并不会有页被淘汰。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/3d81ef5cad0f9125115e92c63680a3f6.png alt=image.png></p><p>虽然通过划分 old 区域 和 young 区域避免了预读失效带来的影响，但是还有个问题无法解决，那就是 Buffer Pool 污染的问题。</p><blockquote><p>什么是 Buffer Pool 污染？
当某一个 SQL 语句<strong>扫描了大量的数据</strong>时，在 Buffer Pool 空间比较有限的情况下，可能会将 <strong>Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了</strong>，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 <strong>Buffer Pool 污染</strong>。
注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。</p></blockquote><p>比如，在一个数据量非常大的表，执行了这条语句：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=k>select</span> <span class=o>*</span> <span class=nx>from</span> <span class=nx>t_user</span> <span class=nx>where</span> <span class=nx>name</span> <span class=nx>like</span> <span class=s>&#34;%xiaolin%&#34;</span><span class=p>;</span>
</span></span></code></pre></div><p>可能这个查询出来的结果就几条记录，但是由于这条语句会发生索引失效，所以这个查询过程是全表扫描的，接着会发生如下的过程：</p><ul><li>从磁盘读到的页加入到 LRU 链表的 old 区域头部；</li><li>当从页里读取行记录时，也就是页被访问的时候，就要将该页放到 young 区域头部；</li><li>接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里；</li><li>如此往复，直到扫描完表中的所有记录。</li></ul><p>经过这一番折腾，原本 young 区域的热点数据都会被替换掉。</p><p>举个例子，假设需要批量扫描：21，22，23，24，25 这五个页，这些页都会被逐一访问（读取页里的记录）。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/e1116880bcc2ee25518d3b6077180da8.png alt=image.png></p><p>在批量访问这些数据的时候，会被逐一插入到 young 区域头部。</p><p><img loading=lazy src=https://raw.githubusercontent.com/roaraeonliou/roaraeonliou.github.io/static/6cea475dd0613750dfc0a9cef61c13c4/d5603461eb809b5098c1925f4275e433.png alt=image.png></p><p>可以看到，原本在 young 区域的热点数据 6 和 7 号页都被淘汰了，这就是 Buffer Pool 污染的问题。</p><blockquote><blockquote><p><strong>怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？</strong></p></blockquote></blockquote><p>像前面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。
LRU 链表中 young 区域就是热点数据，只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。
MySQL 是这样做的，进入到 young 区域条件增加了一个<strong>停留在 old 区域的时间判断</strong>。
具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：</p><ul><li>如果后续的访问时间与第一次访问的时间<strong>在某个时间间隔内</strong>，那么<strong>该缓存页就不会被从 old 区域移动到 young 区域的头部</strong>；</li><li>如果后续的访问时间与第一次访问的时间<strong>不在某个时间间隔内</strong>，那么<strong>该缓存页移动到 young 区域的头部</strong>；</li></ul><p>这个间隔时间是由 <code>innodb_old_blocks_time</code> 控制的，默认是 1000 ms。</p><p>也就说，<strong>只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部</strong>，这样就解决了 Buffer Pool 污染的问题 。</p><p>另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。</p><h3 id=324-脏页什么时候会被刷入磁盘>3.2.4 脏页什么时候会被刷入磁盘？<a hidden class=anchor aria-hidden=true href=#324-脏页什么时候会被刷入磁盘>#</a></h3><p>引入了 Buffer Pool 后，当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，但是磁盘中还是原数据。</p><p>因此，脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘。</p><p>可能大家担心，如果在脏页还没有来得及刷入到磁盘时，MySQL 宕机了，不就丢失数据了吗？</p><p>这个不用担心，InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。</p><p>下面几种情况会触发脏页的刷新：</p><ul><li>当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；</li><li>Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li><li>MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；</li><li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；</li></ul><p>在我们开启了慢 SQL 监控后，如果你发现**「偶尔」会出现一些用时稍长的 SQL**，这可能是因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致数据库操作抖动。</p><p>如果间断出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。</p><h2 id=33-总结>3.3 总结<a hidden class=anchor aria-hidden=true href=#33-总结>#</a></h2><p>Innodb 存储引擎设计了一个<strong>缓冲池（<em>Buffer Pool</em>）</strong>，来提高数据库的读写性能。</p><p>Buffer Pool 以页为单位缓冲数据，可以通过 <code>innodb_buffer_pool_size</code> 参数调整缓冲池的大小，默认是 128 M。</p><p>Innodb 通过三种链表来管理缓页：</p><ul><li>Free List （空闲页链表），管理空闲页；</li><li>Flush List （脏页链表），管理脏页；</li><li>LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去。；</li></ul><p>InnoDB 对 LRU 做了一些优化，我们熟悉的 LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化：</p><ul><li>将 LRU 链表 分为<strong>young 和 old 两个区域</strong>，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。</li><li>当**「页被访问」且「 old 区域停留时间超过 <code>innodb_old_blocks_time</code> 阈值（默认为1秒）」**时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。</li></ul><p>可以通过调整 <code>innodb_old_blocks_pct</code> 参数，设置 young 区域和 old 区域比例。</p><p>在开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可因为脏页在刷新到磁盘时导致数据库性能抖动。如果在很短的时间出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://roaraeonliou.github.io/tags/%E7%AC%94%E8%AE%B0/>笔记</a></li><li><a href=https://roaraeonliou.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a></li><li><a href=https://roaraeonliou.github.io/tags/mysql/>MySQL</a></li></ul><nav class=paginav><a class=prev href=https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql/><span class=title>« Prev</span><br><span>MySQL</span>
</a><a class=next href=https://roaraeonliou.github.io/posts/interviewnotes/database/mysql/mysql%E9%9D%A2%E8%AF%95/><span class=title>Next »</span><br><span>MySQL面试</span></a></nav></footer><div id=comments><script src=https://giscus.app/client.js data-repo=RoaraeonLiou/roaraeonliou.github.io data-repo-id=R_kgDOMIxQ4w data-category=Announcements data-category-id=DIC_kwDOMIxQ484CgZUR data-mapping=title data-strict=1 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://roaraeonliou.github.io/>RLTEA BLOG</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>